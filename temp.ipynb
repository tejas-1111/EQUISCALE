{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import CustomDataset, MultiEpochsDataLoader\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb90ec88ddc94b789d4dbfdd8be729b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0068c3289db643e48c2e9de5a0dd1be9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# See if MultiEpochsDataLoader is faster than normal pytorch dataloader\n",
    "len = 1000\n",
    "a = np.random.rand(len, 3).astype(np.float32)\n",
    "a[:, 0] = np.arange(len).astype(np.float32)\n",
    "b = np.rint(np.random.rand(len))\n",
    "c = np.rint(np.random.rand(len))\n",
    "\n",
    "dataset = CustomDataset(a, b, c)\n",
    "d1 = DataLoader(dataset, batch_size=256, shuffle=True, num_workers=4, pin_memory=True, persistent_workers=True)\n",
    "d2 = MultiEpochsDataLoader(dataset, batch_size=256, shuffle=True, num_workers=4, pin_memory=True, persistent_workers=True)\n",
    "\n",
    "for _ in tqdm(range(10)):\n",
    "    for __ in range(10):\n",
    "        for ___ in range(500):\n",
    "            for batch in d2:\n",
    "                pass\n",
    "\n",
    "for _ in tqdm(range(10)):\n",
    "    for __ in range(10):\n",
    "        for ___ in range(500):\n",
    "            for batch in d1:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[4.0000, 0.3833, 0.1364],\n",
      "        [6.0000, 0.3211, 0.7636]]), tensor([1, 0]), tensor([1, 0])]\n",
      "[tensor([[8.0000, 0.1532, 0.0182],\n",
      "        [9.0000, 0.2500, 0.5472]]), tensor([0, 0]), tensor([1, 1])]\n",
      "[tensor([[7.0000e+00, 4.4640e-03, 4.1253e-01],\n",
      "        [5.0000e+00, 1.4409e-01, 8.3813e-01]]), tensor([0, 1]), tensor([0, 1])]\n",
      "[tensor([[2.0000, 0.0451, 0.7399],\n",
      "        [1.0000, 0.8743, 0.2458]]), tensor([1, 0]), tensor([1, 0])]\n",
      "[tensor([[3.0000, 0.4744, 0.5670],\n",
      "        [0.0000, 0.7924, 0.7799]]), tensor([1, 1]), tensor([0, 0])]\n",
      "__________________________\n",
      "[tensor([[1.0000, 0.8743, 0.2458],\n",
      "        [0.0000, 0.7924, 0.7799]]), tensor([0, 1]), tensor([0, 0])]\n",
      "[tensor([[8.0000, 0.1532, 0.0182],\n",
      "        [2.0000, 0.0451, 0.7399]]), tensor([0, 1]), tensor([1, 1])]\n",
      "[tensor([[7.0000e+00, 4.4640e-03, 4.1253e-01],\n",
      "        [9.0000e+00, 2.5000e-01, 5.4719e-01]]), tensor([0, 0]), tensor([0, 1])]\n",
      "[tensor([[5.0000, 0.1441, 0.8381],\n",
      "        [6.0000, 0.3211, 0.7636]]), tensor([1, 0]), tensor([1, 0])]\n",
      "[tensor([[4.0000, 0.3833, 0.1364],\n",
      "        [3.0000, 0.4744, 0.5670]]), tensor([1, 1]), tensor([1, 0])]\n"
     ]
    }
   ],
   "source": [
    "# Check if MultiEpochsDataLoader shuffles data\n",
    "\n",
    "len = 10\n",
    "a = np.random.rand(len, 3).astype(np.float32)\n",
    "a[:, 0] = np.arange(len).astype(np.float32)\n",
    "b = np.rint(np.random.rand(len))\n",
    "c = np.rint(np.random.rand(len))\n",
    "\n",
    "dataset = CustomDataset(a, b, c)\n",
    "d = MultiEpochsDataLoader(dataset, batch_size=2, shuffle=True, num_workers=4, pin_memory=True, persistent_workers=True)\n",
    "\n",
    "r1 = []\n",
    "r2 = []\n",
    "for e in range(2):\n",
    "    for batch in d:\n",
    "        if e == 0:\n",
    "            r1.append(batch)\n",
    "        else:\n",
    "            r2.append(batch)\n",
    "\n",
    "for batch in r1:\n",
    "    print(batch)\n",
    "print(\"__________________________\")\n",
    "for batch in r2:\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[100, 100, 100, 100, 100, 100, 100, 100, 100, 100]\n"
     ]
    }
   ],
   "source": [
    "# Check if MultiEpochsDataLoader gives all samples as inputs\n",
    "len = 10\n",
    "a = np.random.rand(len, 3).astype(np.float32)\n",
    "a[:, 0] = np.arange(len).astype(np.float32)\n",
    "b = np.rint(np.random.rand(len))\n",
    "c = np.rint(np.random.rand(len))\n",
    "count = [0 for _ in range(len)]\n",
    "\n",
    "dataset = CustomDataset(a, b, c)\n",
    "d = MultiEpochsDataLoader(dataset, batch_size=2, shuffle=True, num_workers=3, pin_memory=True, persistent_workers=True)\n",
    "\n",
    "print(count)\n",
    "for _ in range(100):\n",
    "    for batch in d:\n",
    "        for idx in batch[0][:, 0]:\n",
    "            count[int(idx)] += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "[8 1 5 0 7 2 9 4 3 6]\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "[0 1 8 5 3 4 7 9 6 2]\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "[9 2 0 6 8 5 3 7 1 4]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "def t(a: np.ndarray):\n",
    "    b = a.copy()\n",
    "    np.random.shuffle(b)\n",
    "    print(b)\n",
    "\n",
    "a = np.arange(10)\n",
    "print(a)\n",
    "t(a)\n",
    "print(a)\n",
    "t(a)\n",
    "print(a)\n",
    "t(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([])\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "a = torch.empty(0)\n",
    "b = torch.ones(16)\n",
    "print(a)\n",
    "print(b)\n",
    "print(torch.concat((a, b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "l = 0.21875\n",
    "h = 0.40625\n",
    "a = \"[\"\n",
    "for c in np.linspace(l, h, 21):\n",
    "    a+= f\"{c:f}, \"\n",
    "a = a[:-2]\n",
    "a += \"]\"\n",
    "print(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
